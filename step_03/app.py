
import gradio as gr 
import whisper
from utils import translate
from functools import partial

output_types = ['txt','vtt','srt','json','tsv']
model = whisper.load_model("medium")
translate_to_srt = partial(translate, model=model)


block = gr.Blocks()

with block:
    gr.Markdown("# ğŸŒ† éŸ³è§†é¢‘å¤„ç†")
    with gr.Row(): 
        with gr.Column() as col1:
            with gr.Box(): 
                with gr.Row().style():
                    inp_video = gr.Video(
                        label="è¾“å…¥è§†é¢‘",
                        type="filepath",
                        mirror_webcam = False
                    )
            # out_format = gr.CheckboxGroup(output_types,label="è¾“å‡ºæ–‡æœ¬ç±»å‹")
            out_format = gr.Dropdown(output_types,label="è¾“å‡ºæ–‡æœ¬ç±»å‹")

        with gr.Column():
            with gr.Tab("å­—å¹•"):
                op_text = gr.Textbox(lines=11)
            with gr.Tab("è§†é¢‘"):
                op_video = gr.Video() 
                gr.Markdown("è§†é¢‘æ·»åŠ å­—å¹•")   
            with gr.Tab("éŸ³é¢‘"):
                op_audio = gr.Audio()                    

        with col1:
            btn = gr.Button("æå–è§†é¢‘å­—å¹•")
            btn.click(translate_to_srt, inputs=[inp_video,out_format], outputs=[op_video, op_text, op_audio]) 
        

    gr.HTML('''
    <div class="footer">
                <p>Model by <a href="https://github.com/openai/whisper" style="text-decoration: underline;" target="_blank">OpenAI</a> 
                </p>
    </div>
    ''')


if __name__ == "__main__":
    block.launch()  # debug = True
